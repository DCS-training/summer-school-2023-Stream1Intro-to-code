{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping an html page (loading and searching it's contents)\n",
    "\n",
    "# Local:  saved in a file on your computer\n",
    "# Remote: somewhere on the web\n",
    "\n",
    "To fully understand this notebook, open the example_html.html file in another tab, and open it's example_html.html's source code in a third tab (or even better: in browser's View>Developer tools). You will see in a minute what is the exact addres sof that file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For scraping, we need a few of different libraries, most notably Beautifulsoup. Let's first import these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simply enter a web page as a string and open it. Afterwards, BeautifulSoup converts it into a BeautifulSoup object which has many interesting functions and attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# website address\n",
    "#page = 'http://www.uebs.ed.ac.uk'\n",
    "\n",
    "# open the url and store the website\n",
    "#website = urlopen(page)\n",
    "\n",
    "# for now we use a local file (os.getcwd() gets the Current Working Directory, aka. the folder you're in)\n",
    "file_url = \"file:///\"+os.getcwd()+\"/example_html.html\"\n",
    "website_source_code = urlopen(file_url)\n",
    "\n",
    "\n",
    "# in another tab: (open the example_html.html file directly in your browser to see how it will look like)\n",
    "# then in your browser, right click and select 'view source', or open developer tools to see the source\n",
    "print(\"Paste this url to your browser to see the demo website (copy the whole thing, together wioth the file:// part):\")\n",
    "print( file_url)\n",
    "\n",
    "# convert the website's content, for this a parser is needed. In this case a html parser\n",
    "soup = BeautifulSoup(website_source_code, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's a complete html of the page, but it's easier to read if you open it's source using the url above\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# .find_all retrieves all tags containing 'h1':\n",
    "h1Tags = soup.find_all('h1')\n",
    "for h1 in h1Tags:\n",
    "    print('Complete tag code: ', h1)\n",
    "    print(\"Just the text in the tag: \", h1.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not work with attributes of tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleTags = soup.find_all('title')\n",
    "for title in titleTags:\n",
    "    print('Complete tag code: ', title)\n",
    "    print(\"Just the text in the tag: \", title.text)\n",
    "    \n",
    "# nothing will be printed. there are no tags <title> </title> there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the html is all about finding components you need:\n",
    "\n",
    "### .find_all( ) will find all things that match criteria, in a list\n",
    "### .find( ) will find just the first item that mathes the criteria\n",
    "\n",
    "You can use it on the whole website, like `a_table = soup.find(\"table\")` or on an element you found before `rows = a_table.find(\"tr\")`\n",
    "\n",
    "You can seek for types of tags, classes or ids  `soup.find(\"h1\")`,  `soup.find(id=\"main_navigation\")`, `soup.find(class=\"warning_message\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it is very frequent to fetch an element by its unique id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_row = soup.find(id='middle_row')\n",
    "\n",
    "print('Complete tag code: ', middle_row)\n",
    "print(\"Just the text in the tag: \", middle_row.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find children:\n",
    "\n",
    "When, like above, a tag contains some children (tags inside it) you can extract them into a list.\n",
    "The example would be above table row `<tr></tr>` includes three table data `<td></td>`\n",
    "    \n",
    "```\n",
    ".findChildren()\n",
    "``` will give you alist with all tags inside of a given tag\n",
    "\n",
    "You can specify exactly which chhildre, if you want, like with the .find(). So you could use `.findChildren(\"tr\")` or `.findChildren(class=\"warning_message\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_row = soup.find(id='middle_row')\n",
    "cells_in_the_row = middle_row.findChildren()\n",
    "for cell in cells_in_the_row:\n",
    "    print('Complete tag code: ', cell, \"Just the text in the tag: \", cell.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can dive deeper into certain tags, for example here you look for all divs from the (CSS) class called hipster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_elements = soup.find_all(\"div\", {\"class\" : \"hipster\" })\n",
    "for element in class_elements:\n",
    "    print('whole tag:\\n', str(element), '\\n')\n",
    "    print('Just the text: ', line.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting all the elements out of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all tables, since we only have 1, use the first in the list at index 0\n",
    "my_table = soup.find_all('table')[0]\n",
    "# or just use: my_table = soup.find('table')\n",
    "\n",
    "# loop the rows and keep the row number\n",
    "row_num = 0\n",
    "for row in my_table.find_all('tr'):\n",
    "    print(\"Row: \"+str(row_num))\n",
    "    row_num = row_num+1\n",
    "\n",
    "    #loop the cells in the row\n",
    "    for cell in row.find_all('td'):\n",
    "        print(\"whole html:\", str(cell)+\" \\tJust content: \"+cell.text)\n",
    "        \n",
    "# if you'd like, try to change this code to use .findChildren( ) rather than .find_all('tr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minitask: Now attempt to scrape something from a real online website:\n",
    "\n",
    "Use the above code to make a list of all the degrees available in business school of University of Edinburgh. \n",
    "\n",
    "1. You will need to get the source of the page the list is on and feed it into the breautiful soup (see code above). (use this url instead of our demo website file://..... use this:  https://www.ed.ac.uk/studying/undergraduate/degrees/index.php?action=view&code=12)\n",
    "2. get the html component that holds all the degrees. Use developer tools to identify what type of component it is (hint: ul stamds for \"unordered list\"). Does this component have a class or an id? How would you get a component when you know it's id? (hint: proxy_degreeList )\n",
    "3. What type of a tag are the actual names of degrees in? (div, a, p, or something else) hint: what tag surround the name of the course?\n",
    "4. Grab children of that type from the component with all names and in a loop, extract only the text of each of them. And print them.\n",
    "\n",
    "\n",
    "I am posting the solution lower down, but do try to solve it by yourself first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy-paste relevant parts of the code from above to start:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only uncover the solutions once you tried to complete the task:\n",
    "    \n",
    "    \n",
    "<details><summary style='color:blue'>CLICK HERE TO SEE THE THE HINT 1.</summary>\n",
    "\n",
    "1. You will need to get the source of the page the list is on and feed it into the breautiful soup (see code above). (use this url instead of our demo website file://..... use this:  https://www.ed.ac.uk/studying/undergraduate/degrees/index.php?action=view&code=12)\n",
    "\n",
    "```\n",
    "file_url = \"https://www.ed.ac.uk/studying/undergraduate/degrees/index.php?action=view&code=12\"\n",
    "website_source_code = urlopen(file_url)\n",
    "soup_degrees_website = BeautifulSoup(website_source_code, 'html.parser')\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details><summary style='color:blue'>CLICK HERE TO SEE THE THE HINT 2.</summary>\n",
    "\n",
    " 2. get the html component that holds all the degrees.  Use developer tools to identify what type of component it is (hint: ul stamds for \"unordered list\").  Does this component have a class or an id? How would you get a component when you know it's id?  (hint: proxy_degreeList )\n",
    "```\n",
    "degrees = soup_degrees_website.find(id='proxy_degreeList')\n",
    " ```   \n",
    "</details>\n",
    "\n",
    "<details><summary style='color:blue'>CLICK HERE TO SEE THE THE HINT 3.</summary>\n",
    "\n",
    " 3. What type of a tag are the actual names of degrees in? (div, a, p, or something else) hint: what tag surround the name of the course?\n",
    "``` \n",
    "for list_item in degrees.findChildren(\"a\"):\n",
    "  ```  \n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "<details><summary style='color:blue'>CLICK HERE TO SEE THE THE HINT 4.</summary>\n",
    "\n",
    "4. Grab children of that type from the component with all names and in a loop, extract only the text of each of them. And print them.\n",
    "```\n",
    "    print(\"Degree Name:\", list_item.text)\n",
    "    ```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
