{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PANDAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Pandas we will work more and more with real data. Many concepts will be familiar to you from Excel and other data-browsing applications.\n",
    "\n",
    "Note: This badge is very long, but opens the door to the world of data science in Python.\n",
    "\n",
    "In this notebook:\n",
    "\n",
    "Pandas\n",
    "- DataDrame = Dict + Excel\n",
    "\n",
    "- accessing, editing and sorting IFs (.loc)\n",
    "\n",
    "- changing with functions: mapping and applying\n",
    "\n",
    "- creating new columns with assign, replace, drop\n",
    "\n",
    "- grouping, indexes and renaming\n",
    "\n",
    "- mini-diary ⭐️⭐️⭐️❓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame - basically like a more powerful Dict + Excel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Keys are column names\n",
    "- Values as Arrays/Lists with rows\n",
    "\n",
    "**DataFrame is to a Dict what Array was to a List**\n",
    "\n",
    "To create a DataFrame we put a Dict it its constructor. But remember that values need to be lists. Like this:\n",
    "\n",
    "```\n",
    "data = pd.DataFrame({'names': ['Judy', 'Kim', 'Shaz'], 'year': [1,1,2] })\n",
    "   ```\n",
    "   \n",
    "You can access DataFrame columns, like you would variables in an object\n",
    "\n",
    "```data.names``` or ```data['names']```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Subsets - get some Rows, get some Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we use them, we'll need to import Pandas once per notebook (it's not a problem if you import them a few times)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'names': ['Judy', 'Kim', 'Shaz', 'Sun'],\n",
    "                     'study_year': [1,1,2,1], \n",
    "                     'avg_grades': [72,61,68,65] })\n",
    "print(data) \n",
    "# notice the constructor function pd.DataFrame(...) basically takes a normal Dictionary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row subset work like with Arrays, above  dataframe[start: ceiling : jump ]\n",
    "print(data[1:3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0:3:2])  # jump every 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a column. The old way.\n",
    "# Notice meta information about names and data types!\n",
    "print(data['names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but quite frequently you would use a . dot notation, like this:\n",
    "print(data.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get individual items\n",
    "print(data.names[0])\n",
    "print(data.names[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get many individual items\n",
    "print(data.names[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change values: the old ('deprecated') way\n",
    "\n",
    "data = pd.DataFrame({'names': ['Judy', 'Kim', 'Shaz', 'Sun'],\n",
    "                     'study_year': [1,1,2,1], \n",
    "                     'avg_grades': [72,61,68,65] })\n",
    "\n",
    "data.names[0] = \"Natasha\" # note that this way is likely to thrown an errror below\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead you would use the new .at or .loc operator. They do the same thing, but loc is more flexible\n",
    "\n",
    "data = pd.DataFrame({'names': ['Judy', 'Kim', 'Shaz', 'Sun'],\n",
    "                     'study_year': [1,1,2,1], \n",
    "                     'avg_grades': [72,61,68,65] })\n",
    "\n",
    "data.loc[0, 'names'] = \"Natasha\" # notice the order of arguments\n",
    "data.loc[2, 'avg_grades'] = 100\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new column to dataframe works just like adding a new key-value pair to a Dict\n",
    "\n",
    "data = pd.DataFrame({'names': ['Judy', 'Kim', 'Shaz', 'Sun'],\n",
    "                     'study_year': [1,1,2,1], \n",
    "                     'avg_grades': [72,61,68,65] })\n",
    "data['department'] = ['business', 'math', 'business', 'medicine']\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify all items in a column\n",
    "data = pd.DataFrame({'names': ['Judy', 'Kim', 'Shaz', 'Sun'],\n",
    "                     'study_year': [1,1,2,1], \n",
    "                     'avg_grades': [72,61,68,65] })\n",
    "data['study_year'] += 1 # same as data['study_year']  = data['study_year']  + 1\n",
    "data['avg_grades'] = 0\n",
    "print(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Side note about print vs implied return:** in Python notebooks there are two ways to 'show' what's going on with code\n",
    "\n",
    "This is a notebook-specific feature that we sort of ignored until now, but now it is becoming important:\n",
    "\n",
    "**print()** - 'show' many things, by 'printing/outputting' them below the cell. \n",
    "\n",
    "- You can print many things, and they will be shown in order you printed them (exaclty like with prinitng on paper)\n",
    "\n",
    "**'implied output/return'** - you know return from functions. One thing can get returned from each function, and then the function 'ends/terminates'. In other words: the return is always the last thing that happens in the function. In notebook cells it works simmilar, but without the word 'return' - the value of the last things that happens in the notebook will be shows underneath it in an Out[] block\n",
    "\n",
    "- Only one thing is in 'Out[]' block. It is the value of the last line in your code. \n",
    "- Some functions do not return anything (eg. print(...) does not). Also assignment = do not return anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all prints are visible, but only the result of the last line is 'Out[]'ed\n",
    "print(3)\n",
    "print(4)\n",
    "print(5)\n",
    "100\n",
    "200\n",
    "300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Shaz'\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assignment does not return anything, so nothing is 'Out[]'ed\n",
    "name = 'Shaz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing does not return anything, so nothing is 'Out[]'ed\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but for example comparison does return a True/False value\n",
    "name == \"Banana\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and here we will both print and return a value. Because why not!\n",
    "print(name)\n",
    "name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Back to the topic...**\n",
    "\n",
    "### Showing/printing DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can ```print()``` DataFrames and they will be arranged into a nice readable format, but you can also return them (make them the last item in your Notetebook cell) and they will be displayed in an even nicer format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'name' : ['Judy', 'Kim', 'Shaz', 'Natt', 'Gill'],\n",
    "                   'surname' : ['OBrien', 'Gunn', 'Dice', 'Johnes', 'Roy'],\n",
    "                   'semester' : [1,1,2,2,1],\n",
    "                   'score' : [3.7, 4.6, 8.2, 2.6, 3.7],\n",
    "                   'penalty' : [0.5, 0.0, 0.8, 0.0, 0.2]})\n",
    "\n",
    "# when printed in a cell it is simple\n",
    "print(\"printed version:\\n\", data)\n",
    "\n",
    "# when returned from a cell it is prettier\n",
    "print(\"'returned' version\") # remember: in Python notebooks, the last line of code gets 'returned' and 'interpreted'\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can produce some simple statistics about numeric values in your data with describe() \n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get information abotu data types and sizes of data you can use info()\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sort_values takes a number of arguments:\n",
    "\n",
    "- ```by``` is a List of columns to sort the data by, in order. First items are sorted by first item in this list. If there is a tie, they are sorted by second item, etc.\n",
    "- ```inplace``` is a True/False value indicating whether the new value should be returned, or put back into the sorted dataframe. Use ```inplace=False``` If you want to print or output data, and use ```inplace=True``` if you want to change your actual data.\n",
    "- ```ascending``` takes either True/False value, or a list of True/False values (if sorting by many columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=['semester','score'],ascending=True,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=['semester','score'],ascending=[False, True],inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=['score', 'penalty'],ascending=True,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will sort the 'data' variable, but not actually return it\n",
    "data.sort_values(by=['surname'],ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but look, it was actually sorted by surname!\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicates with drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we learn how to remove duplicates, I will show you how to create some:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiplying items combines them. Multiplying item by x is like adding it to itself x many times\n",
    "\n",
    "print(3 * 3)\n",
    "print('3' * 3)\n",
    "print([3] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can be combined with actual adding\n",
    "print([1,1,1] + [2,2])\n",
    "print(['sales'] * 3 + ['marketting']*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some duplicates and remove them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "door_signs = pd.DataFrame({'department':['sales'] * 3 + ['marketing']*5 + ['r&d'] * 4,\n",
    "                        'floor':[1,2,3,1,2,3,3,3,1,1,1,2]})\n",
    "door_signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "door_signs.sort_values(by='floor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "door_signs.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could drop duplicates in only one column, but keep in mind that the order in which data was will become very meaningful. Have a look at below examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "door_signs = pd.DataFrame({'department':['sales'] * 3 + ['marketing']*5 + ['r&d'] * 4,\n",
    "                        'floor':[1,2,3,1,2,3,3,3,1,1,1,2]})\n",
    "offices.drop_duplicates(subset='department')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "door_signs = pd.DataFrame({'department':['sales'] * 3 + ['marketing']*5 + ['r&d'] * 4,\n",
    "                        'floor':[1,2,3,1,2,3,3,3,1,1,1,2]})\n",
    "door_signs.drop_duplicates(subset='floor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting only some items (you might have seen this before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "door_signs = pd.DataFrame({'department':['sales'] * 3 + ['marketing']*5 + ['r&d'] * 4,\n",
    "                        'floor':[1,2,3,1,2,3,3,3,1,1,1,2]})\n",
    "\n",
    "# pick only those on floor 1\n",
    "door_signs.loc[door_signs['floor'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or above floor 1\n",
    "# pick only those on floor 1\n",
    "door_signs.loc[door_signs['floor'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or within a range\n",
    "door_signs.loc[door_signs['department'].isin(['sales','marketing'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or use many conditions with &\n",
    "door_signs.loc[ (door_signs['department'].isin(['sales','marketing'])) & (door_signs['floor'] > 1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping columns values with .map( ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously when we used map, it was a python method, into which we had to pass the list we wanted to map.\n",
    "\n",
    "```map(mapping_function, my_list)```\n",
    "\n",
    "That was a bit confusing, becuase methods usually are called on objects. It would make more sense for map to work like this:\n",
    "\n",
    "```my_list.map(mapping_function)```\n",
    "\n",
    "And Pandas give us the ability to do exacltyu that! Well... on Arrays, not Lists, but that's close enough.\n",
    "\n",
    "```my_data_frame.map(mapping_function)```\n",
    "\n",
    "**YOU CAN CHAIN .MAP( )** which makes certain tasks much simpler, like in \n",
    "\n",
    "```name.map(mapping_function_1).map(mapping_function_2)```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'fruits' : [\"banana\",  \"kiwi\", \"apple\"]})\n",
    "\n",
    "data['lengths'] = data['fruits'].map(len)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But first... a short catchup on lambda functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traditional function definition looks like this:\n",
    "data = pd.DataFrame({'fruits' : [\"banana\",  \"kiwi\", \"apple\"]})\n",
    "\n",
    "def first_letter(word):\n",
    "    return word[0]\n",
    "\n",
    "print(first_letter(\"banana\"))\n",
    "\n",
    "\n",
    "# and then you can use this function's NAME in a map\n",
    "\n",
    "data['first_letters'] = data['fruits'].map(first_letter)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick recap about lambda functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'lambda function' is python's simplified syntax for defining functions.\n",
    "# they do not really have a name, but rather you can put function definition right into your code\n",
    "# function definition looks like this: \n",
    "# lambda inputs: outputs\n",
    "\n",
    "data = pd.DataFrame({'fruits' : [\"banana\",  \"kiwi\", \"apple\"]})\n",
    "\n",
    "first_letter = lambda word: word[0] # this replaces function definition. But is a bit harder to read\n",
    "# you sort of put a function in a variable. It can still be used like a function:\n",
    "print(first_letter(\"banana\"))\n",
    "\n",
    "\n",
    "data['first_letters'] = data['fruits'].map(first_letter)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but most commonly lambdas are used in situations where calculation is quick and simple\n",
    "# and there is no need to give it a special name, or to reuse it later \n",
    "\n",
    "data = pd.DataFrame({'fruits' : [\"banana\",  \"kiwi\", \"apple\"]})\n",
    "\n",
    "data['first_letters'] = data['fruits'].map(lambda word: word[0])\n",
    "\n",
    "data\n",
    "# this is THE MOST COMMON SCENARIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another example\n",
    "offices = pd.DataFrame({'department':['sales'] * 3 + ['marketing']*5 + ['r&d'] * 4,\n",
    "                        'floor':[1,2,3,1,2,3,3,3,1,1,1,2]})\n",
    "offices['floor_signs'] = offices['floor'].map(lambda floor: f\"Floor {floor}\")\n",
    "offices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offices = pd.DataFrame({'department':['sales'] * 3 + ['marketing']*5 + ['r&d'] * 4, \n",
    "                        'floor':[1,2,3,1,2,3,3,3,1,1,1,2]})\n",
    "\n",
    "floor_names = {1: 'Ground Floor', 2: 'Main Floor', 3: \"Roof Floor\"}\n",
    "\n",
    "offices['floor_signs'] = offices['floor'].map(lambda floor: floor_names[floor] )\n",
    "offices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up data with .map( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an **example of chaining** ```.map( )``` to clean up data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is so messy! Read it. Do you see any patterns? How could it be fixed?\n",
    "\n",
    "offices = pd.DataFrame({\n",
    "    'department': ['-Sales-', 'sales  ', '-SALES-', 'marketing', 'MARKETING', '-marketing-',\n",
    "                   'Marketing', '  marketing', '-R&D-', ' r&d', 'r&d  ', 'r&d'],\n",
    "    'floor':[1,2,3,1,2,3,3,3,1,1,1,2]\n",
    "})\n",
    "offices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "department_codes = {'sales': \"SAL\", 'marketing': \"MAR\", 'r&d': \"RND\" }\n",
    "\n",
    "# Let's create lambdas which will clean it up, one source of messiness at a time:\n",
    "remove_space_and_dash = lambda word: word.strip().strip('-')\n",
    "to_lower_case = lambda word: word.lower()\n",
    "dept_name_to_code = lambda dept_name: department_codes[dept_name]\n",
    "\n",
    "# mapping - add new column, with cleaned up values\n",
    "offices['dept_code'] = offices['department'].map(remove_space_and_dash).map(to_lower_case).map(dept_name_to_code)\n",
    "offices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame and Higher Order Functions: .map( ) and .applymap( ) and  .apply( ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these three do something very simmilar, but in simplest terms:\n",
    "\n",
    "- **map( )** works with column items, one at a time. Use it to represent each item as another item.\n",
    "- **applymap( )** works with whole DataFrame (all columns). like above, but more columns.\n",
    "- **apply( )** access each row, or columns, and represent it as one value (reduce it to one value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's a silly example:\n",
    "# map() changes column \n",
    "\n",
    "people = pd.DataFrame({\n",
    "    'firstname': ['Jill', 'Ryu', 'Rashni'],\n",
    "    'lastname':['McDoughal', 'Kawasaki', 'Ng']\n",
    "})\n",
    "\n",
    "to_upper_case = lambda word: word.upper()\n",
    "people['firstname'] = people['firstname'].map(to_upper_case)\n",
    "people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's a silly example:\n",
    "# applymap() changes all columns \n",
    "\n",
    "people = pd.DataFrame({\n",
    "    'firstname': ['Jill', 'Ryu', 'Rashni'],\n",
    "    'lastname':['McDoughal', 'Kawasaki', 'Ng']\n",
    "})\n",
    "\n",
    "to_upper_case = lambda word: word.upper()\n",
    "people = people.applymap(to_upper_case)\n",
    "# this could also be written with lambda right in the map:\n",
    "# people = people.applymap(lambda word: word.upper())\n",
    "\n",
    "people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's a silly example:\n",
    "# applymap() changes all columns \n",
    "# note: function takes the column as input\n",
    "\n",
    "people = pd.DataFrame({\n",
    "    'firstname': ['Jill', 'Ryu', 'Rashni'],\n",
    "    'lastname':['McDoughal', 'Kawasaki', 'Ng']\n",
    "})\n",
    "\n",
    "join_names = lambda column: f\"{column['firstname']} {column['lastname']}\"\n",
    "\n",
    "people['fullname'] = people.apply(join_names, axis='columns')\n",
    "people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And another set of examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs']\n",
    "})\n",
    "\n",
    "def shortened(word):\n",
    "    if len(word) >= 10:\n",
    "        return f\"{word[0:7]}...\"\n",
    "    else:\n",
    "        return word\n",
    "    \n",
    "    \n",
    "# note, above function could also be written with a ternary operator:\n",
    "# shortened = lambda word: word if len(word) < 10 else f\"{word[0:7]}...\"\n",
    "\n",
    "\n",
    "# map is used on a column\n",
    "foods['label'] = foods['name'].map(shortened) # just one column\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs']\n",
    "})\n",
    "\n",
    "\n",
    "new_foods = foods.applymap(to_upper_case) # applymap is used on a while dataframe\n",
    "new_foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20]\n",
    "})\n",
    "\n",
    "\n",
    "string_from_row = lambda column: f\"{column['name']} from {column['supplier']} suits {column['diet']} diet\"\n",
    "\n",
    "# apply is used to create a new column, but has access to all columns \n",
    "foods['label'] = foods.apply(string_from_row, axis='columns')\n",
    "foods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But what does the 'axis=' do in apply function?\n",
    "\n",
    "it describes the dimension in which function is applier (i.e. 1 == rows,  0 == columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = pd.DataFrame([[11,22,33]] *5, columns=['ones','twos','threes'])\n",
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.apply(np.sum, axis = 0) # this returns a new 1d array. axis 0 means columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.apply(np.sum, axis = 1) # this returns a new 1d array. axis 1 means rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More of data cleaning and preparation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate a new column from rows with ```.assign( )```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Returns a new object with all original columns in addition to new ones. \n",
    "# Existing columns that are re-assigned will be overwritten.\"\n",
    "\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20]\n",
    "})\n",
    "\n",
    "foods = foods.assign(student_price = foods['price']*0.9, available = True)\n",
    "foods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is special :D For a change, **assign( ) does not change the original dataframe**. That's because if you specified 'inplace=True' it would just add a column called 'inplace' and put values True in every row of that column. It's just a peculiar price we need to pay for the power of assign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20]\n",
    "})\n",
    "\n",
    "foods.assign(student_price = foods['price']*0.9, inplace=True) # this will go wrong!\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = foods.assign(student_price = foods['price']*0.9, inplace=True) \n",
    "#let's try again, and catch result. inplace does something unexpected\n",
    "foods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete a column with ```.drop( )```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20]\n",
    "})\n",
    "\n",
    "foods.drop('supplier',axis='columns',inplace=True)\n",
    "foods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace some data with ```.replace( )```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: **NaN** stands for \"Not a Number\" and is sort of like **None**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace in ALL COLUMNS\n",
    "\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0],\n",
    "    'sold_since_year': [2018, 2015, 0, 2012, 0, 0]\n",
    "})\n",
    "\n",
    "# replace value 0 with NaN \n",
    "foods.replace(0, np.nan, inplace=True)\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace in SELECTED COLUMNS\n",
    "\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0],\n",
    "    'sold_since_year': [2018, 2015, 0, 2012, 0, 0]\n",
    "})\n",
    "\n",
    "# replace value 0 with NaN - IN ALL COLUMNS\n",
    "foods['sold_since_year'].replace(0, np.nan, inplace=True)\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace many items with one replacement\n",
    "\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0],\n",
    "    'sold_since_year': [2018, 2015, 0, 2012, 0, 0]\n",
    "})\n",
    "\n",
    "foods.replace(['Vegetarian','Vegan'],'No Meat',inplace=True)\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace many items with many replacements\n",
    "\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0],\n",
    "    'sold_since_year': [2018, 2015, 0, 2012, 0, 0]\n",
    "})\n",
    "\n",
    "foods.replace(['Vegetarian','Vegan', 'Meat'],['VEGE', 'VEGA', 'MEAT'],inplace=True)\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace many items with many replacements. Use a dictionary.\n",
    "# VERY USEFUL FOR LOOKUPS! eg. when you have a table that translates eg. id into name\n",
    "\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0],\n",
    "    'sold_since_year': [2018, 2015, 0, 2012, 0, 0],\n",
    "    'delivery':['Monday', 'Saturday', 'Saturday', 'Tuesday', 'Sunday', 'Wednesday'],\n",
    "\n",
    "})\n",
    "\n",
    "foods.replace({'Saturday': 'Weekend', 'Sunday': 'Weekend'},inplace=True)\n",
    "foods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple statistics for all data and grouped by a value, using  groupby()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe provide a full set of all statistical methods. If you need something specific, always look in the documentation https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0],\n",
    "    'sold_since_year': [2018, 2015, 0, 2012, 0, 0]\n",
    "})\n",
    "\n",
    "# mean of all prices\n",
    "print( foods['price'].mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of all prices, grouped by diet\n",
    "print( foods['price'].groupby(foods['diet']).mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( foods['price'].groupby(foods['diet']).max() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( foods['price'].groupby(foods['diet']).median() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index - the most important part of your data (should be unique, but does not have to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not specify the index in your data, python will just use continuous numbers starting from 0 (like 0,1,2,3,4,...). Have a look at the dataframes you created before. Index is that number to the left. It's sort of like a row name in Excel.\n",
    "\n",
    "```.set_index(a_column_name)``` will set a column with name a_column_name to be the index\n",
    "\n",
    "```drop=False``` will make the old column stay (it will sort-of get duplicated and you'd have two identical columns: the original one, and the new index column)\n",
    "\n",
    "You could also have many columns act as  indexes, but we will not go into that. If you wanted to do that, just pass a List of column names to set_index rather than one column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first with no index. Noice numbers on the left-hand size\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0],\n",
    "    'sold_since_year': [2018, 2015, 0, 2012, 0, 0]\n",
    "})\n",
    "\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn one of the columns into an index\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0],\n",
    "    'sold_since_year': [2018, 2015, 0, 2012, 0, 0]\n",
    "}).set_index('name')\n",
    "\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... and also keep that column as it was, without drop = False\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0],\n",
    "    'sold_since_year': [2018, 2015, 0, 2012, 0, 0]\n",
    "}).set_index('name', drop=False)\n",
    "\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so now you can use your index to get whole rows from the dataframe\n",
    "# this is a bit cleaner than indexes 1,2,3,4... depending on your data\n",
    "foods.loc[['Bagel']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming columns and rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can rename rows, columns, or both. Just specify a dict where key is the OLD VALUE, and value is the NEW VALUE.\n",
    "\n",
    "```{old_value: new_value, old_value_2: new_value_2}```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we change names of some rows. Basically it means that we change values in the index\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0]\n",
    "}).set_index('name',  drop=False)\n",
    "\n",
    "# rename NAMES of rows\n",
    "foods.rename(index = {'Bagel':'BAGEL', 'Tap Water':'WATER'}, inplace=True)\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we change names of some columns.\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0]\n",
    "}).set_index('name',  drop=False)\n",
    "\n",
    "# rename NAMES of columns and rows. (not values)\n",
    "foods.rename(columns={'supplier':'from', 'price':'pounds'},inplace=True)\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can also do both at the same time\n",
    "# AND you can use string functions like str.upper, str.title, etc\n",
    "\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0]\n",
    "}).set_index('name', drop=True)\n",
    "\n",
    "foods.rename(index = str.upper, columns=str.title ,inplace=True)\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And just like when you use str. functions above, you can use your own functions\n",
    "# by defining them before, or using 'on the spot' lambda functions\n",
    "\n",
    "# You can also use your own lambda functions for mapping old value to new value\n",
    "\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0]\n",
    "}).set_index('name', drop=True)\n",
    "\n",
    "\n",
    "# in example below we use lambda function for index, and pre-defined function for columns\n",
    "# just so you see you can do both\n",
    "\n",
    "def add_the(word):\n",
    "    return f\"The {word}\"\n",
    "\n",
    "foods.rename(index = (lambda name: name[0:3]), columns=add_the ,inplace=True)\n",
    "foods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categories - Grouping results by a range of values. Use ```pd.data.cut( data, bins, labels )``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we want to categorise our data into particular groups by value. Given a set of values, we want to decide in which range they belong.\n",
    "\n",
    "Imagine a bunch of student exam scores (70,54,40,66) that we want to translate into grades (A,B,C,D,F).\n",
    "\n",
    "We will need a key of where one grade ends and another starts. One way to call them are bins (like buckets/containers) and our task is put each score in one of these bins.\n",
    "\n",
    "- F is (0, 40]\n",
    "- D is (40, 50]\n",
    "- C is (50, 60]\n",
    "- B is (60, 70]\n",
    "- A is (70, 100]\n",
    "\n",
    "Note: \n",
    "\n",
    "- '(' means the value is included in the bin\n",
    "- '[' means the value is excluded\n",
    "\n",
    "In panda you could describe it as ```[(0, 40] < (40, 50] < (50, 60] < (60, 70] < (70, 100]]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "student_scores = [40,42,46,54,60,63,66,70, 72]\n",
    "\n",
    "bins = [0,40,50,60,70,100]\n",
    "grades = [\"F\",\"D\",\"C\",\"B\",\"A\"]\n",
    "\n",
    "# note: labels (eg. grades) are optional, but very useful\n",
    "\n",
    "# cut will categorise\n",
    "categories = pd.cut(student_scores, bins, labels=grades, right=False)\n",
    "print(categories) # print shows how are values are categorised, and also what do categories mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want the rightmost elements to be included in the smaller category (eg. for score 40 to be an 'F')\n",
    "# use right=True argument, or just no right argument (True is a default)\n",
    "categories = pd.cut(student_scores, bins, labels=grades, right=True)\n",
    "print(categories)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you use ```pd.cut(student_scores, bins, labels=[\"F\",\"D\",\"C\",\"B\",\"A\"])``` the resulting object contains information about \n",
    "\n",
    "- which category each of your data oints belongs to\n",
    "- what are the categories and their boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_scores = [40,54,60,66,70]\n",
    "bins = [0,40,50,60,70,100]\n",
    "labels = [\"F\",\"D\",\"C\",\"B\",\"A\"]\n",
    "categories = pd.cut(student_scores, bins, labels=labels)\n",
    "\n",
    "print(categories)\n",
    "print()\n",
    "print( categories.tolist() )\n",
    "print(categories.codes) # in older versions this was called .labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.value_counts(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are times when cummulative sum is very useful. it will add all items until now, but order is peculiar\n",
    "print(pd.value_counts(categories).cumsum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AND FINALLY: Add a new column with bin values. Very useful for labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame( {'student_scores': [40,54,60,66,70]} )\n",
    "bins = [0,40,50,60,70,100]\n",
    "labels = [\"F\",\"D\",\"C\",\"B\",\"A\"]\n",
    "\n",
    "data['grade'] = pd.cut(data['student_scores'], bins=bins, labels=labels)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(start = '20200101', end = '20220101',periods=4)\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(start = '20200101',freq='M',periods=4)\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quickly create some fake data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some fake data quickly: combine np.arange( ) with .reshape()\n",
    "\n",
    "# grab 12 numbers\n",
    "np.arange(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folde them into a 2D array\n",
    "np.arange(12).reshape((3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and put some meaning to them\n",
    "data = pd.DataFrame(np.arange(12).reshape((3, 4)),\n",
    "                    index=['Glasgow', 'Inverness', 'St Andrews'],\n",
    "                    columns=['Jan', 'Feb','Mar','Apr'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is even better with random numbers, eg\n",
    "np.random.randint(low = 20, high = 28, size = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raining_days = pd.DataFrame(np.random.randint(low = 20, high = 28, size = 12).reshape((3, 4)),\n",
    "                    index=['Glasgow', 'Inverness', 'St Andrews'],\n",
    "                    columns=['Jan', 'Feb','Mar','Apr'])\n",
    "raining_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⭐️⭐️⭐️💥 What you learned in this session: Three stars and a wish \n",
    "**In your own words** write in your Learn diary:\n",
    "\n",
    "- 3 things you yould like to remember from this badge\n",
    "- 1 thing you wish to understand better in the future or a question you'd like to ask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
